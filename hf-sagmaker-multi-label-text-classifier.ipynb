{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label Content Moderation with HuggingFace and PyTorch on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make sure the Amazon SageMaker SDK is updated\n",
    "!pip install \"sagemaker\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a few libraries that will be needed\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os, time, tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets role for executing training job and set a few variables\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"hf-content-mod\"\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HF's Content Moderation Classification Dataset is constructed by choosing 4 largest classes from the original corpus. Each class contains near equal distributed test samples. The total number of training samples is 75 for training and demo purposes only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-06 01:22:59--  https://escalona-robocar.s3.amazonaws.com/content_moderation_csv.tgz\n",
      "Resolving escalona-robocar.s3.amazonaws.com (escalona-robocar.s3.amazonaws.com)... 52.216.21.83, 52.217.97.12, 52.216.111.35, ...\n",
      "Connecting to escalona-robocar.s3.amazonaws.com (escalona-robocar.s3.amazonaws.com)|52.216.21.83|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10258 (10K) [application/gzip]\n",
      "Saving to: ‘content_moderation_csv.tgz’\n",
      "\n",
      "content_moderation_ 100%[===================>]  10.02K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-06 01:22:59 (182 MB/s) - ‘content_moderation_csv.tgz’ saved [10258/10258]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download and extract our custom dataset\n",
    "!wget -nc https://escalona-robocar.s3.amazonaws.com/content_moderation_csv.tgz\n",
    "tf = tarfile.open('content_moderation_csv.tgz')\n",
    "tf.extractall()\n",
    "!rm -fr content_moderation_csv.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data and add a header\n",
    "train = pd.read_csv('./content_moderation_csv/train.csv')\n",
    "train.columns = ['label', 'title', 'description']\n",
    "\n",
    "# read testing data and add a header\n",
    "test = pd.read_csv('./content_moderation_csv/test.csv')\n",
    "test.columns = ['label', 'title', 'description']\n",
    "\n",
    "# write the files with header\n",
    "train.to_csv(\"content_moderation_csv/hf-train.csv\", index=False)\n",
    "test.to_csv(\"content_moderation_csv/hf-test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Scorched Earth</td>\n",
       "      <td>Ridiculous behavior that cannot be tolerated a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Read a book</td>\n",
       "      <td>Wow... your worldview is apparently informed b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spreading Joy</td>\n",
       "      <td>Lets make some fact based statements. Pleae sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Healthy debate</td>\n",
       "      <td>How about introducing Vukovich to you, Bob1946...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Low IQ</td>\n",
       "      <td>The president makes himself an easy target bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Thanks for your response</td>\n",
       "      <td>That is point I'm trying to make. We seem to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Sister of man who died in Vancouver police cus...</td>\n",
       "      <td>My flight was subcontracted to another carrier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Removal</td>\n",
       "      <td>this is *&amp;^%ing outrageous. The prosecutor sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Night Vision Goggles</td>\n",
       "      <td>You better not send me on a witch hunt or else...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>The stupid</td>\n",
       "      <td>The profoundly stupid have spoken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>Post removal</td>\n",
       "      <td>The ignorance and bigotry comes from your post...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Dropping Tip rate</td>\n",
       "      <td>As the price of things go up especially eating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Miltary Base Barter</td>\n",
       "      <td>I bet China would be happy to help Puerto Rico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Sue happy</td>\n",
       "      <td>Coming from a representative of the most sue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>Cash Business</td>\n",
       "      <td>Will our power &amp; water costs will go up?  Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Worthiness</td>\n",
       "      <td>I don't think the lesson has to do with eviden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>Science Requirements</td>\n",
       "      <td>Eight years after the first high-quality publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Conquering White Males</td>\n",
       "      <td>And let's not forget the original chemically p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>Go Ducks!</td>\n",
       "      <td>From the article it appears the defense in an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>Milestone</td>\n",
       "      <td>Mccallum stopped drinking in 2002.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>Spiraling into the toilet</td>\n",
       "      <td>Alaska's great because of \"this man.\"  Alaska'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>Father?</td>\n",
       "      <td>Isn't the person a deadbeat father?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>Piece of Pie</td>\n",
       "      <td>Everybody want's a piece of the pie. You will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>Humiliating</td>\n",
       "      <td>An \"abject lesson\" is a lesson that is painful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>Babeling</td>\n",
       "      <td>He  is a vanilla, boring, bible-thumper who ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>Boycott</td>\n",
       "      <td>Right on the money Gary Crum. And if they hide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>Rally</td>\n",
       "      <td>The only safe space needed would be for conser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>Road improvement</td>\n",
       "      <td>I prefer consumption taxes so people have more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>Lack of education?</td>\n",
       "      <td>I guess you do not need any type of education ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>Lowering the numbers</td>\n",
       "      <td>Just because in the past people's mental healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>Integrated Economies</td>\n",
       "      <td>adding to that there is a lot of American inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>Basic Math?</td>\n",
       "      <td>What a poor economy Ecuador has. That's a 62% ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>Anyone supporting sexual predator enabler,  HR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>Bwahahaha</td>\n",
       "      <td>she said Bwahahaha for 34 days straight!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>Complaints</td>\n",
       "      <td>Well, it appears the staff needs trashing. If ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>Remain Ignorant</td>\n",
       "      <td>All the folks you mention are dead. The Southe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>Grabbing my ankles</td>\n",
       "      <td>I'll continue to bending over and grabbing my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>Follow along now</td>\n",
       "      <td>I totally understand what murder is.  This is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>Pitching in a groove</td>\n",
       "      <td>He actually pitched pretty well last night. Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>Already Satiated</td>\n",
       "      <td>This guy's book is a little late. Our rage is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>Higher prices</td>\n",
       "      <td>Prices in Australia are quite a bit higher tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>Future of the nation?</td>\n",
       "      <td>Do you really want this to happen to the rest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>Snarky Misfire</td>\n",
       "      <td>Wow beth, did you just follow up a snarky misf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>Dazed</td>\n",
       "      <td>Dazed, befuddled &amp; confused?  Just like trump.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>Apples to Apples</td>\n",
       "      <td>That's an apples and oranges comparison. The c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>Church's evolution</td>\n",
       "      <td>The Church evolved into a community dependent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>Brazilian pockets</td>\n",
       "      <td>Marcello Caira. Very nice. Sold the company ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>a Takeover</td>\n",
       "      <td>This is an appalling decision in allowing the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>No point in futher discussion</td>\n",
       "      <td>This is a perfect example of why you will not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              title  \\\n",
       "0       1                                     Scorched Earth   \n",
       "1       1                                        Read a book   \n",
       "2       2                                      spreading Joy   \n",
       "3       2                                     Healthy debate   \n",
       "4       4                                             Low IQ   \n",
       "5       2                           Thanks for your response   \n",
       "6       1  Sister of man who died in Vancouver police cus...   \n",
       "7       1                                            Removal   \n",
       "8       3                               Night Vision Goggles   \n",
       "9       4                                         The stupid   \n",
       "10      3                                       Post removal   \n",
       "11      2                                  Dropping Tip rate   \n",
       "12      1                                Miltary Base Barter   \n",
       "13      4                                          Sue happy   \n",
       "14      2                                      Cash Business   \n",
       "15      2                                         Worthiness   \n",
       "16      4                               Science Requirements   \n",
       "17      1                             Conquering White Males   \n",
       "18      2                                         Go Ducks!    \n",
       "19      2                                          Milestone   \n",
       "20      1                          Spiraling into the toilet   \n",
       "21      1                                            Father?   \n",
       "22      3                                       Piece of Pie   \n",
       "23      4                                        Humiliating   \n",
       "24      4                                           Babeling   \n",
       "25      1                                            Boycott   \n",
       "26      1                                              Rally   \n",
       "27      2                                   Road improvement   \n",
       "28      4                                 Lack of education?   \n",
       "29      1                               Lowering the numbers   \n",
       "30      2                               Integrated Economies   \n",
       "31      4                                        Basic Math?   \n",
       "32      1                                              POTUS   \n",
       "33      4                                          Bwahahaha   \n",
       "34      1                                         Complaints   \n",
       "35      1                                    Remain Ignorant   \n",
       "36      4                                 Grabbing my ankles   \n",
       "37      3                                   Follow along now   \n",
       "38      2                               Pitching in a groove   \n",
       "39      1                                   Already Satiated   \n",
       "40      2                                      Higher prices   \n",
       "41      1                              Future of the nation?   \n",
       "42      1                                     Snarky Misfire   \n",
       "43      4                                              Dazed   \n",
       "44      2                                   Apples to Apples   \n",
       "45      2                                 Church's evolution   \n",
       "46      4                                  Brazilian pockets   \n",
       "47      1                                         a Takeover   \n",
       "48      4                      No point in futher discussion   \n",
       "\n",
       "                                          description  \n",
       "0   Ridiculous behavior that cannot be tolerated a...  \n",
       "1   Wow... your worldview is apparently informed b...  \n",
       "2   Lets make some fact based statements. Pleae sp...  \n",
       "3   How about introducing Vukovich to you, Bob1946...  \n",
       "4   The president makes himself an easy target bec...  \n",
       "5   That is point I'm trying to make. We seem to b...  \n",
       "6   My flight was subcontracted to another carrier...  \n",
       "7   this is *&^%ing outrageous. The prosecutor sho...  \n",
       "8   You better not send me on a witch hunt or else...  \n",
       "9                  The profoundly stupid have spoken.  \n",
       "10  The ignorance and bigotry comes from your post...  \n",
       "11  As the price of things go up especially eating...  \n",
       "12  I bet China would be happy to help Puerto Rico...  \n",
       "13   Coming from a representative of the most sue ...  \n",
       "14  Will our power & water costs will go up?  Will...  \n",
       "15  I don't think the lesson has to do with eviden...  \n",
       "16  Eight years after the first high-quality publi...  \n",
       "17  And let's not forget the original chemically p...  \n",
       "18  From the article it appears the defense in an ...  \n",
       "19                 Mccallum stopped drinking in 2002.  \n",
       "20  Alaska's great because of \"this man.\"  Alaska'...  \n",
       "21                Isn't the person a deadbeat father?  \n",
       "22  Everybody want's a piece of the pie. You will ...  \n",
       "23  An \"abject lesson\" is a lesson that is painful...  \n",
       "24  He  is a vanilla, boring, bible-thumper who ju...  \n",
       "25  Right on the money Gary Crum. And if they hide...  \n",
       "26  The only safe space needed would be for conser...  \n",
       "27  I prefer consumption taxes so people have more...  \n",
       "28  I guess you do not need any type of education ...  \n",
       "29  Just because in the past people's mental healt...  \n",
       "30  adding to that there is a lot of American inve...  \n",
       "31  What a poor economy Ecuador has. That's a 62% ...  \n",
       "32  Anyone supporting sexual predator enabler,  HR...  \n",
       "33         she said Bwahahaha for 34 days straight!!!  \n",
       "34  Well, it appears the staff needs trashing. If ...  \n",
       "35  All the folks you mention are dead. The Southe...  \n",
       "36   I'll continue to bending over and grabbing my...  \n",
       "37  I totally understand what murder is.  This is ...  \n",
       "38  He actually pitched pretty well last night. Gr...  \n",
       "39  This guy's book is a little late. Our rage is ...  \n",
       "40  Prices in Australia are quite a bit higher tha...  \n",
       "41  Do you really want this to happen to the rest ...  \n",
       "42  Wow beth, did you just follow up a snarky misf...  \n",
       "43     Dazed, befuddled & confused?  Just like trump.  \n",
       "44  That's an apples and oranges comparison. The c...  \n",
       "45   The Church evolved into a community dependent...  \n",
       "46  Marcello Caira. Very nice. Sold the company ou...  \n",
       "47  This is an appalling decision in allowing the ...  \n",
       "48  This is a perfect example of why you will not ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the training data\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-175748383800/hf-content-mod/train/hf-train.csv\n",
      "s3://sagemaker-us-east-1-175748383800/hf-content-mod/test/hf-test.csv\n"
     ]
    }
   ],
   "source": [
    "# upload training and testing data to Amazon S3\n",
    "inputs_train = sagemaker_session.upload_data(\"content_moderation_csv/hf-train.csv\", bucket=bucket, key_prefix='{}/train'.format(prefix))\n",
    "inputs_test = sagemaker_session.upload_data(\"content_moderation_csv/hf-test.csv\", bucket=bucket, key_prefix='{}/test'.format(prefix))\n",
    "print(inputs_train)\n",
    "print(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Threat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Insult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "0   Toxic\n",
       "1  Benign\n",
       "2  Threat\n",
       "3  Insult"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep in mind the classes used in this dataset\n",
    "classes = pd.read_csv('./content_moderation_csv/classes.txt', header=None)\n",
    "classes.columns = ['label']\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT large uncased\n",
    "https://huggingface.co/bert-large-uncased\n",
    "#### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "\t'model_name_or_path':'bert-large-uncased',\n",
    "\t'output_dir':'/opt/ml/model',\n",
    "    'train_file':'/opt/ml/input/data/train/hf-train.csv',\n",
    "    'validation_file':'/opt/ml/input/data/test/hf-test.csv',\n",
    "    'do_train':True,\n",
    "    'do_eval':True,\n",
    "    'num_train_epochs': 1,\n",
    "    'save_total_limit': 1,\n",
    "\t# add your remaining hyperparameters\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.10.0/examples/pytorch/text-classification\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.6.1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates Hugging Face estimator\n",
    "huggingface_estimator_bert = HuggingFace(\n",
    "\tentry_point='run_glue.py', # note we are pointing to the processing script in HF repo\n",
    "\tsource_dir='./examples/pytorch/text-classification',\n",
    "\tinstance_type='ml.p3.16xlarge',\n",
    "\tinstance_count=1, #note that this training uses just a single EC2 instance\n",
    "\trole=role,\n",
    "\tgit_config=git_config,\n",
    "\ttransformers_version='4.6.1',\n",
    "\tpytorch_version='1.7.1',\n",
    "\tpy_version='py36',\n",
    "\thyperparameters = hyperparameters,\n",
    "    disable_profiler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_path='s3://{}/{}/train'.format(bucket, prefix)\n",
    "testing_path='s3://{}/{}/test'.format(bucket, prefix)\n",
    "# starting the train job\n",
    "huggingface_estimator_bert.fit({\"train\": training_path, \"test\": testing_path}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time - JobStatus - SecondaryStatus\n",
      "------------------------------\n",
      "01:35 - Completed - Completed\n"
     ]
    }
   ],
   "source": [
    "# check the status of the training job\n",
    "client = boto3.client(\"sagemaker\")\n",
    "describe_response = client.describe_training_job(TrainingJobName=huggingface_estimator_bert.latest_training_job.name)\n",
    "\n",
    "print ('Time - JobStatus - SecondaryStatus')\n",
    "print('------------------------------')\n",
    "print (time.strftime(\"%H:%M\", time.localtime()), '-', describe_response['TrainingJobStatus'] + \" - \" + describe_response['SecondaryStatus'])\n",
    "\n",
    "# uncomment this for monitoring the job status...\n",
    "#job_run_status = describe_response['TrainingJobStatus']\n",
    "#while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "#    describe_response = client.describe_training_job(TrainingJobName=huggingface_estimator_bert.latest_training_job.name)\n",
    "#    job_run_status = describe_response['TrainingJobStatus']\n",
    "#    print (time.strftime(\"%H:%M\", time.localtime()), '-', describe_response['TrainingJobStatus'] + \" - \" + describe_response['SecondaryStatus'])\n",
    "#    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** Make sure the training job is completed before running the \"Inference\" section below.\n",
    "\n",
    "You can verify this by running the previous cell and getting JobStatus = \"Completed\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = sagemaker.huggingface.HuggingFaceModel(\n",
    "env={ 'HF_TASK':'text-classification' },\n",
    "model_data=huggingface_estimator_bert.model_data,\n",
    "role=role,\n",
    "transformers_version=\"4.6.1\",\n",
    "pytorch_version=\"1.7.1\",\n",
    "py_version='py36',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "# create SageMaker Endpoint with the HF model\n",
    "predictor = huggingface_model.deploy(\n",
    "initial_instance_count=1,\n",
    "instance_type=\"ml.g4dn.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_3', 'score': 0.4378846287727356}] Insult\n"
     ]
    }
   ],
   "source": [
    "# example request (you always need to define \"inputs\"). You can try with your own content text here...\n",
    "data = {\n",
    "   #\"inputs\": \"Hugging Face now has a Deep Reinforcement Learning course!\"\n",
    "   \"inputs\": \"You are not the sharpest tool in the shed are you?\"\n",
    "}\n",
    "\n",
    "response = predictor.predict(data)\n",
    "print(response, classes['label'][int(response[0]['label'][-1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT average inference time: 0.038 secs,\n"
     ]
    }
   ],
   "source": [
    "# let us run a quick performance test\n",
    "sum_BERT=0\n",
    "for i in range(1, 1000):\n",
    "    a_time = float(time.time())\n",
    "    result_BERT = predictor.predict(data)\n",
    "    b_time = float(time.time())\n",
    "    sum_BERT = sum_BERT + (b_time - a_time)\n",
    "    #print(b_time - a_time)\n",
    "avg_BERT = sum_BERT/1000\n",
    "print('BERT average inference time: {:.3f}'.format(avg_BERT), 'secs,')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below for cleaning-up your content moderation endpoint\n",
    "predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exteding your next training job to use a distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Hugging Face Trainer supports SageMaker’s data parallelism library. If your training script uses the Trainer API, \n",
    "#you only need to define the distribution parameter in the Hugging Face Estimator. Below is the configuration for running \n",
    "#training on smdistributed Data Parallel\n",
    "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "\n",
    "# creates the next Hugging Face estimator using a distributed setup\n",
    "#When you are ready to scale the number of instances, you can do this with SageMaker Python SDK estimator function by setting your instance_count.\n",
    "huggingface_estimator_bert = HuggingFace(\n",
    "\tentry_point='run_glue.py', # note we are pointing to the processing script in HF repo\n",
    "\tsource_dir='./examples/pytorch/text-classification',\n",
    "\tinstance_type='ml.p3.16xlarge',\n",
    "\tinstance_count=2, #Instead of the eight GPUs on a single p3.16xlarge, you now have 16 GPUs across two identical instances.\n",
    "\trole=role,\n",
    "\tgit_config=git_config,\n",
    "\ttransformers_version='4.6.1',\n",
    "\tpytorch_version='1.7.1',\n",
    "\tpy_version='py36',\n",
    "\thyperparameters = hyperparameters,\n",
    "    disable_profiler=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_path='s3://{}/{}/train'.format(bucket, prefix)\n",
    "testing_path='s3://{}/{}/test'.format(bucket, prefix)\n",
    "# starting the train job\n",
    "huggingface_estimator_bert.fit({\"train\": training_path, \"test\": testing_path}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time - JobStatus - SecondaryStatus\n",
      "------------------------------\n",
      "02:47 - Completed - Completed\n"
     ]
    }
   ],
   "source": [
    "# check the status of the training job\n",
    "client = boto3.client(\"sagemaker\")\n",
    "describe_response = client.describe_training_job(TrainingJobName=huggingface_estimator_bert.latest_training_job.name)\n",
    "\n",
    "print ('Time - JobStatus - SecondaryStatus')\n",
    "print('------------------------------')\n",
    "print (time.strftime(\"%H:%M\", time.localtime()), '-', describe_response['TrainingJobStatus'] + \" - \" + describe_response['SecondaryStatus'])\n",
    "\n",
    "# uncomment this for monitoring the job status...\n",
    "#job_run_status = describe_response['TrainingJobStatus']\n",
    "#while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "#    describe_response = client.describe_training_job(TrainingJobName=huggingface_estimator_bert.latest_training_job.name)\n",
    "#    job_run_status = describe_response['TrainingJobStatus']\n",
    "#    print (time.strftime(\"%H:%M\", time.localtime()), '-', describe_response['TrainingJobStatus'] + \" - \" + describe_response['SecondaryStatus'])\n",
    "#    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-base-python-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
